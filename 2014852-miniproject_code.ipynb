{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"2014852-miniproject_code.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"MKfkGg7ZSdN1"},"source":["# **Sentimental Analysis Using Twitter Dataset**"]},{"cell_type":"markdown","metadata":{"id":"IC69bTbASdOr"},"source":["## Mini Project\n","\n","\n","*   Name : Shekhar Saxena\n","*   University Roll No : 2014852\n","*   Course : B.Tech.\n","*   Branch : CSE\n","*   Semester : 3rd\n","*   Section : A \n","\n"]},{"cell_type":"markdown","metadata":{"id":"BQde9qGsSdO0"},"source":["## **Problem Statement**\n","\n","* To predict people's sentiment using **Twitter Dataset**"]},{"cell_type":"markdown","metadata":{"id":"ZGDEfmVUSdO2"},"source":["## **Importing Libraries**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"OFfEX-J8SdO4"},"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YlFnbODoSdO8"},"source":["## **Loading Dataset**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"4dSwpH2iSdO-","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1624601866747,"user_tz":-330,"elapsed":479,"user":{"displayName":"SHEKHAR SAXENA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7cLCC9ufQKcrXTNUo2rO-4KMW9L0KxbHtsYGnog=s64","userId":"15861822707765083955"}},"outputId":"1f15c1ec-4efe-458b-9971-f9eadcbe7edb"},"source":["twitter_df = pd.read_csv('../input/twitter-sentiment-analysis-hatred-speech/train.csv',encoding='utf8',engine='python')\n","# twitter_df\n","# # Dropping the id column\n","twitter_df = twitter_df.drop(['id'], axis = 1)\n","# # Ensuring that the coulmn is dropped sucessfully\n","twitter_df"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-e0f33be7c0ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtwitter_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twitter.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# twitter_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# # Dropping the id column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtwitter_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # Ensuring that the coulmn is dropped sucessfully\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                     \u001b[0;34m'are \"c\", \"python\", or \"python-fwf\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 )\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2387\u001b[0m             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m         )\n\u001b[1;32m   2391\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'twitter.csv'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7t5iZoOC0HOP","executionInfo":{"status":"ok","timestamp":1624601858520,"user_tz":-330,"elapsed":447,"user":{"displayName":"SHEKHAR SAXENA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7cLCC9ufQKcrXTNUo2rO-4KMW9L0KxbHtsYGnog=s64","userId":"15861822707765083955"}},"outputId":"70e9a98a-f4cb-4cb9-f2ff-350eca974c2d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HhN88DrlSdPL"},"source":["## **Task 3 : Exploring Dataset**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"UwRxKjO6SdPp"},"source":["sns.heatmap(twitter_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"qlzG_fszSdPs"},"source":["twitter_df['length'] = twitter_df['tweet'].apply(len)\n","twitter_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"uYd_ww76SdPx"},"source":["positive = twitter_df[twitter_df['label']==0]\n","positive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"kfuYAgDtSdP4"},"source":["negative = twitter_df[twitter_df['label']==1]\n","negative"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33ekQWodSdP5"},"source":["## **Plotting the WordCloud**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"zVy2e3_zSdP7"},"source":["sentences = twitter_df['tweet'].tolist()\n","sentences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"KBdRWl49SdP8"},"source":["sentences_as_one_string = \" \".join(sentences)\n","sentences_as_one_string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"waLurIgCSdQA"},"source":["!pip install WordCloud\n","from wordcloud import WordCloud\n","\n","plt.figure(figsize=(20,20))\n","plt.imshow(WordCloud().generate(sentences_as_one_string))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CSo7I3cxSdQB"},"source":["## **Data Cleaning : Remove Punctuation From Text**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"WpSDTJWfSdQC"},"source":["import string\n","string.punctuation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"h4VqYHhaSdQJ"},"source":["Test = 'Good morning beautiful people :)... I am having fun learning Machine learning and AI!!'\n","Test_punc_removed = []\n","for char in Test: \n","    if char not in string.punctuation:\n","        Test_punc_removed.append(char)\n","        \n","Test_punc_removed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"H4tMtmsJSdQK"},"source":["# Join the characters again to form the string.\n","Test_punc_removed_join = ''.join(Test_punc_removed)\n","Test_punc_removed_join"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qm2w27bdSdQM"},"source":["## **Data Cleaning : Remove Stopwords**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"fY7AktvQSdQO"},"source":["from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))\n","stop_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"CuOU55NPSdQQ"},"source":["Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n","Test_punc_removed_join_clean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"rtzh2vi9SdQR"},"source":["Test_punc_removed_join_clean_joined = ''.join(Test_punc_removed_join_clean)\n","Test_punc_removed_join_clean_joined"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u_wF0FH-SdQW"},"source":["## **Count Vectorization/ Tokenization**"]},{"cell_type":"markdown","metadata":{"id":"BmPLc_zuSdQZ"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"code","metadata":{"trusted":true,"id":"gNsfNKl1SdQc"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","sample_data = ['This is the first paper.','This document is the second paper.','And this is the third one.','Is this the first paper?']\n","\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(sample_data)\n","\n","print(vectorizer.get_feature_names())\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"Mxk5MgqISdQh"},"source":["print(X.toarray())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DvK1D7AkSdQi"},"source":["## **Creating Pipeline for Data Cleaning : Removing Punctuations, Removing Stopwords and Count Vectorization**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"gxsTbX-_SdQj"},"source":["def message_cleaning(message):\n","    Test_punc_removed = [char for char in message if char not in string.punctuation]\n","    Test_punc_removed_join = ''.join(Test_punc_removed)\n","    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n","    return Test_punc_removed_join_clean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"6eI96hErSdQp"},"source":["twitter_df_clean = twitter_df['tweet'].apply(message_cleaning)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ZIBaQzuJSdQq"},"source":["print(twitter_df_clean[5]) # show the cleaned up version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"60cP-1h1SdQs"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","vectorizer = CountVectorizer(analyzer = message_cleaning, dtype = np.uint8)\n","twitter_countvectorizer = vectorizer.fit_transform(twitter_df['tweet'])\n","\n","print(vectorizer.get_feature_names())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"iyCa2XUCSdQt"},"source":["print(twitter_countvectorizer.toarray())  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"I3_SuuwRSdQv"},"source":["twitter_countvectorizer.shape\n","twitter = pd.DataFrame(twitter_countvectorizer.toarray())\n","X = twitter\n","X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"cUYP7Gh1SdQx"},"source":["y = twitter_df['label']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7cdZT0xhSdQ4"},"source":["## **Train the Naive Bayes Classifier Model**"]},{"cell_type":"markdown","metadata":{"id":"kanQIKnGSdQ5"},"source":["Naive Bayes classifiers are a collection of classification algorithms based on Bayesâ€™ Theorem. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other."]},{"cell_type":"markdown","metadata":{"id":"lB_U9rrLSdQ7"},"source":["The dataset is divided into two parts, namely, feature matrix and the response vector.\n"]},{"cell_type":"markdown","metadata":{"id":"3umBVbI3SdQ9"},"source":["* naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. \n","* They require a small amount of training data to estimate the necessary parameters.\n","* Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. "]},{"cell_type":"code","metadata":{"trusted":true,"id":"DKrXcwtZSdQ-"},"source":["X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"k49VI5ocSdQ_"},"source":["y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"TA8omimTSdRA"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"PSNGgWW9SdRB"},"source":["from sklearn.naive_bayes import MultinomialNB\n","\n","NB_classifier = MultinomialNB()\n","NB_classifier.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tPVPGCRhSdRC"},"source":["## **Assess the performance of Trained Model**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"HLff1mJeSdRD"},"source":["# Predicting the Test set results\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","y_predict_test = NB_classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_predict_test)\n","sns.heatmap(cm, annot=True)\n","\n","print(classification_report(y_test, y_predict_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEYdIGDLSdRE"},"source":["### **Thank You!!**"]}]}